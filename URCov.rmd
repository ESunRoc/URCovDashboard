---
title: "COVID Dashboard for the UofR"
date: '`r format(Sys.time(), "%B %d, %Y")`'
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    source_code: embed
    vertical_layout: fill
runtime: shiny
---

```{r global, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(tidyverse)
library(zoo)
library(RcppRoll)
library(gridExtra)
library(grid)
library(plotly)
library(htmlwidgets)

source("dataproc.r")
```

Total Cases {data-navmenu="Cases"}
=====================================  
    
Inputs {.sidebar}
-----------------------------------------------------------------------

The total number of cases as a function of time.  
This graph show more or less what we expect to see; over time, as more tests are conducted, we do expect to see more cases. Ultimately what we'd like to be seeing is a plateau, but given the rates at which cases are spiking all over the country, expecting that of UR is probably unfair.  
  


**Cases in past 24 hours:**  
`r data[nrow(data), 3]`  
**Tests in past 24 hours:**  
`r data[nrow(data), 2]`  
**Positivity Rate in Past 24 Hours:**  
`r data[nrow(data), 4]*100`\%  

Row 
-----------------------------------------------------------------------

### Raw lineplot

```{r, echo=FALSE, eval=TRUE}
cumlcases <- ggplot(data, aes(x = Date, y = totcases)) +
              geom_line() +
              scale_y_continuous(breaks=seq(0, max(data$totcases)+10 ,10)) +  
              labs(x = "Date", y = "Total Cases", title = "Cumulative cases as a function of time")
cc <- ggplotly(cumlcases, height=650, width=1100)
cc
```


Total Testing {data-navmenu="Testing"}
=====================================  
Inputs {.sidebar}
-----------------------------------------------------------------------


Total tests conducted. Again, this is more or less what we expect to see. Over time, the number of total tests conducted (assuming they don't simply *stop* testing people) will continue to increase without limit. What is the rate of this increase (explored in greater detail via other charts). To highlight here are August 16-17, where the first glut of students began to arrive back on campus, and November 16-17, when the University began use of the so-called "Rapid" tests. The true reliability rate of these latter tests is unknown, especially when used on asymptomatic persons, so while I would like to be able to distinguish between the types of tests used, this is made *very* difficult by the lack of test-specific data from the university.  


**Cases in past 24 hours:**  
`r data[nrow(data), 3]`  
**Tests in past 24 hours:**  
`r data[nrow(data), 2]`  
**Positivity Rate in Past 24 Hours:**  
`r data[nrow(data), 4]*100`\%  

Row 
-----------------------------------------------------------------------

### Raw lineplot

```{r, eval=TRUE, echo=FALSE}
cumltests <- ggplot(data, aes(x = Date, y = tottests)) +
              geom_line() +
              labs(x = "Date", y = "Number of Tests", title = "Cumulative Testing as a function of time")
ct <- ggplotly(cumltests, height=650, width=1100)
ct
```


Daily (+) Rate {data-navmenu="Positivity Rates"}
=====================================  
Inputs {.sidebar}
-----------------------------------------------------------------------

Daily positivity rate. This is perhaps the most important statistic that can be provided when talking about COVID-19 in general terms. Why? Well, because it's a standardized metric. Positivity rate is simply the number of positive tests divided by the number of tests conducted. Therefore, a state like ND, that may only conduct 10-15,000 tests per day, can be directly equated to, say, CA, which may conduct 100-200,000 tests per day. And here it is where we see the UofR is being less-than-transparent. These numbers don't look great for them. They'd look much better if more people were tested, however. This is because, primarily, of a handful of days where testing was in the single digits but a single digit number of cases was also found. In reality this is likely not representative of the true population, but since the true population size is unknown, we can't actually say this and thus, cannot actually say it's definitely a statistical outlier.

**Date:**  
`r  data[nrow(data),1]`  
**Cases in past 24 hours:**  
`r data[nrow(data), 3]`  
**Tests in past 24 hours:**  
`r data[nrow(data), 2]`  
**Positivity Rate in Past 24 Hours:**  
`r data[nrow(data), 4]*100`\%  

Row {.tabset}
-----------------------------------------------------------------------

### Raw lineplot

```{r, echo=FALSE, eval=TRUE}
dailyposrate <- ggplot(data, aes(x = Date, y = daily.prate)) +
                geom_line() + 
                labs(x = "Date", y = "Positivity Rate", title = "Daily positivity rate",
                     subtitle = "Aligned right")
dpr <- ggplotly(dailyposrate, height=650, width=1100)
dpr
```



### Smoothed with a GAM

```{r, echo=FALSE, eval=TRUE}
GAM.dailyposrate <- ggplot(data, aes(x = Date, y = daily.prate)) +
                    geom_smooth(method = "gam", size = 1) + 
                    labs(x = "Date", y = "Positivity Rate", title = "Daily positivity rate",
                         subtitle = "Aligned right")
GAM.dpr <- ggplotly(GAM.dailyposrate, height=650, width=1100)
GAM.dpr
```



Rolling (+) Rate {data-navmenu="Positivity Rates"}
=====================================  
Inputs {.sidebar}
-----------------------------------------------------------------------
Rolling Average Positivity Rate (window of n=7). By using a rolling average of the daily positivity rate over a window of 1 week, we accomplish a similar feat to smoothing it with a GAM while still retaining information that may otherwise have been glossed over. Further, it provides a metric that many states/local governments use in determining the severity of a given outbreak (eg, previous iterations of NY State's travel advisory). While there is an argument to be made for using static windows of 14 days, or 2 weeks, as this is what NY uses in determining if a "pause" must be initiated, I feel like that's a bit misleading of a statistic. For one, cases don't simply "disappear" after that 14 day window finishes and we move into the next. So while, yes, a 7 day rolling average doesn't do a perfect job of capturing and charting active cases, I feel like it does a better enough job of it to justify its use vs a static window.  
  
  
**Cases in past 24 hours:**  
`r data[nrow(data), 3]`  
**Tests in past 24 hours:**  
`r data[nrow(data), 2]`  
**Positivity Rate in Past 24 Hours:**  
`r data[nrow(data), 4]*100`\%  


Row {.tabset}
-----------------------------------------------------------------------

### Raw lineplot

```{r, eval=TRUE, echo=FALSE}
rollposrate <- ggplot(data, aes(x = Date, y = rolldaily.prate)) +
                geom_line() + 
                labs(x = "Date", y = "Positivity Rate", title = "7 day rolling positivity rate",
                     subtitle = "Aligned right")
rpr <- ggplotly(rollposrate, height=650, width=1100)
rpr
```




### Smoothed with a GAM

```{r, echo=FALSE, eval=TRUE}
GAM.rollposrate <- ggplot(data, aes(x = Date, y = rolldaily.prate)) +
                    geom_smooth(method = "gam", size = 1) + 
                    labs(x = "Date", y = "Positivity Rate", title = "7 day rolling positivity rate",
                         subtitle = "Aligned right")
GAM.rpr <- ggplotly(GAM.rollposrate, height=650, width=1100)
GAM.rpr
```


A Note About Positivity Rates {data-navmenu="Positivity Rates"}
=====================================

### Positivity Rates of 100\%

There are now a handful of days where the number of tests conducted is smaller than the number of positive cases recorded. At the time of writing (12/28/2020), those dates are: 10/27/20, 12/26/20, 12/27/20, 12/28/20. Prior to this time, I chose to record days on which this unfortunate condition was met as having "0"\% positivity rate. This isn't correct, obviously, but the alternatives were not reporting the day (which was infeasible since there were cases on those days), reporting a divide by 0 error (infeasible since this would graphically result in the same as above), or setting the positivity rate to infinity (infeasible due to its impact on the rolling positivity rate).  
The previous method sufficed should there only be one or two days where the testing failed to report an accurate positivity rate, but now that there are 4 such days, a number I fully expect to increase, this isn't a tenable solution. As such, the new method is to set the positivity rate for such days to be 100\%. This, too, is not ideal given the impact that it will have on the rolling statistics, but this is a rather appropriate penalty for inadequate testing on those days.  
At this time, this penalty is constant; that is, regardless of whether there were 0 tests conducted with 1 case self-reported, or 2 tests conducted with 20 cases self reported, the positivity rate will be set to 100\%. In the future, this may change to a linear penalty, but I'm yet to make a decision on how best to address that. I will update this section in the future should such changes be made. Again, please contact me at `elisun@me.com` with any suggestions/comments/critiques.  

Rolling tests/day {data-navmenu="Testing"}
=====================================  
Inputs {.sidebar}
-----------------------------------------------------------------------
  
Rolling average tests conducted per day (window n=7). Charting the number of tests conducted is really more an exercise in keeping the University honest than actually checking the degree of spread. The University said early on that they would be conducting approximately 400 random surveillance tests per week on asymptomatic students. They said they wouldn't be testing on weekends, so this rolling average should hover around 80, for the most part, dipping when there are several weekend days included. Suffice it to say this is not what we see. We do see a spike around the time students were brought back to campus, and again when the University secured rapid tests, but in between these spikes, there was simply not enough testing. Or maybe there was. I can't say if their weekly testing regimin is statistically significant or not since I don't know this number.  
**NOTE:**  
Since the creation of this dashboard, Dean Runner responded to an email expressing my concerns and questions regarding the underlying data. According to this reply, there were approximately 3200 students. To quote Dean Runner on the number 400 was reached: "The number 400 was determined in consultation with Dr. Rob Strawderman, the Chair of Biostatistics in the Medical Center, who worked with the team to identify an appropriate threshold at which we could be confident that a certain number of positive results in a week would indicate a certain level of infection increase."  
My thanks to Dean Runner for this information.

**Date:**  
`r  data[nrow(data),1]`  
**Cases in past 24 hours:**  
`r data[nrow(data), 3]`  
**Tests in past 24 hours:**  
`r data[nrow(data), 2]`  
**Positivity Rate in Past 24 Hours:**  
`r data[nrow(data), 4]*100`\%  

Row {.tabset}
-----------------------------------------------------------------------

### Raw lineplot

```{r, echo=FALSE, eval=TRUE}
rolltestsgraph <- ggplot(data, aes(x=Date, y=rolltests)) + 
                    geom_line()+
                    labs(x="Date", y="Tests Conducted", title = "7 day rolling tests per day",
                         subtitle = "Aligned Right")
rtg <- ggplotly(rolltestsgraph, height=650, width=1100)
rtg
```


### Smoothed with a GAM

```{r, echo=FALSE, eval=TRUE}
GAM.rolltestsgraph <- ggplot(data, aes(x=Date, y=rolltests)) + 
                        geom_smooth(method = "gam", size = 1) +
                        labs(x="Date", y="Tests Conducted", title = "7 day rolling tests per day",
                             subtitle = "Aligned Right")
GAM.rtg <- ggplotly(GAM.rolltestsgraph, height=650, width=1100)
GAM.rtg
```


Cases per day {data-navmenu="Cases"}
=====================================  
Inputs {.sidebar}
-----------------------------------------------------------------------
  
Number of new cases per day. This is rather self-explanatory. On its own, this number has several problems. First, it isn't standardized, which makes it impossible to compare to other areas. Second, it has a strict upper bound. It is possible (however unlikely) that the true number of cases per day is orders of magnitude greater than what is actually captured through the performed testing. But if only 7 people are tested, you will find at most 7 cases (or you would, if almost 50\% of the University's cases were not self-reported. But that's a totally different, even larger, problem.) The main value of this number is its enabling of the creation of other metrics, such as daily/rolling (+) rate(s).  
As another note, to preempt the thought, no, testing does not result in more cases. Testing allows you to *see* the cases that are there. This narrative that comes from the top down in this country of "Oh we have cases *because* we test" is totally full of it and really just a tactic to deny science and reality.

**Date:**  
`r  data[nrow(data),1]`  
**Cases in past 24 hours:**  
`r data[nrow(data), 3]`  
**Tests in past 24 hours:**  
`r data[nrow(data), 2]`  
**Positivity Rate in Past 24 Hours:**  
`r data[nrow(data), 4]*100`\%  

Row {.tabset}
-----------------------------------------------------------------------

### Raw lineplot

```{r, echo=FALSE, eval=TRUE}
casesperday <- ggplot(data, aes(x=Date, y=Positive)) + 
                geom_line()+
                labs(x = "Date", y = "Cases", title = "New cases per day")
cpd <- ggplotly(casesperday, height=650, width=1100)
cpd
```



### Smoothed with a GAM

```{r, echo=FALSE, eval=TRUE}
GAM.casesperday <- ggplot(data, aes(x=Date, y=Positive)) + 
                    geom_smooth()+
                    labs(x = "Date", y = "Cases", title = "New cases per day")
GAM.cpd <- ggplotly(GAM.casesperday, height=650, width=1100)
GAM.cpd
```


Tests per day {data-navmenu="Testing"}
=====================================  
Inputs {.sidebar}
-----------------------------------------------------------------------
  
Average tests performed per day. The same as rolling average tests per day, but markedly worse for the reasons mentioned in "Rolling (+) Rate." Not without value, just eclipsed if you are looking for a sense of change over time.  
**NOTE:**  
Since the creation of this dashboard, Dean Runner responded to an email expressing my concerns and questions regarding the underlying data. According to this reply, there were approximately 3200 students. To quote Dean Runner on the number 400 was reached: "The number 400 was determined in consultation with Dr. Rob Strawderman, the Chair of Biostatistics in the Medical Center, who worked with the team to identify an appropriate threshold at which we could be confident that a certain number of positive results in a week would indicate a certain level of infection increase."  
My thanks to Dean Runner for this information.  


**Cases in past 24 hours:**  
`r data[nrow(data), 3]`  
**Tests in past 24 hours:**  
`r data[nrow(data), 2]`  
**Positivity Rate in Past 24 Hours:**  
`r data[nrow(data), 4]*100`\%  
 

Row {.tabset}
-----------------------------------------------------------------------

### Raw lineplot

```{r, echo=FALSE, eval=TRUE}
testsperday <- ggplot(data, aes(x=Date, y=Tests)) + 
                geom_line()+
                labs(x = "Date", y = "Tests", title = "Tests per day")
tpd <- ggplotly(testsperday, height=650, width=1100)
tpd
```



### Smoothed with a GAM

```{r, echo=FALSE, eval=TRUE}
GAM.testsperday <- ggplot(data, aes(x=Date, y=Tests)) + 
                    geom_smooth(method = "gam", size=1)+
                    labs(x = "Date", y = "Tests", title = "Tests per day")
GAM.tpd <- ggplotly(GAM.testsperday, height=650, width=1100)
GAM.tpd
```


Average Tests per Unit Time {data-navmenu="Testing"}
=====================================  
Inputs {.sidebar}
-----------------------------------------------------------------------
  
Average tests per day per week/fortnight. This is primarily for keeping the University honest. For similar reasons as outlined in "Rolling tests/day," this metric allows us to see just how many tests the University is conducting, on average, over time. By blocking the average by week, we hopefully reduce the variation created by potentially having more than 2 weekend (ie, "low to zero" testing days) days included in the average at any given time. We also block by fortnight (2 weeks, for the uninitiated) to simulate the "14-day windows" that NYS uses as blocks.   
**NOTE:**  
Since the creation of this dashboard, Dean Runner responded to an email expressing my concerns and questions regarding the underlying data. According to this reply, there were approximately 3200 students. To quote Dean Runner on the number 400 was reached: "The number 400 was determined in consultation with Dr. Rob Strawderman, the Chair of Biostatistics in the Medical Center, who worked with the team to identify an appropriate threshold at which we could be confident that a certain number of positive results in a week would indicate a certain level of infection increase."  
My thanks to Dean Runner for this information.  


**Cases in past 24 hours:**  
`r data[nrow(data), 3]`  
**Tests in past 24 hours:**  
`r data[nrow(data), 2]`  
**Positivity Rate in Past 24 Hours:**  
`r data[nrow(data), 4]*100`\%  

Row {.tabset}
-----------------------------------------------------------------------

### 7 day blocks

```{r, echo=FALSE, eval=TRUE}
oneweek.avgtests <- ggplot(oneweekavg, aes(x=as.numeric(Group.1), y=Tests)) +
                      geom_line() + 
                      labs(x="Weeks since August 1", title="Average Tests Over Time Period", 
                           subtitle = "Temporal mean, t=7")
owat <- ggplotly(oneweek.avgtests, height=625, width=1100)
owat
```




### 14 day blocks

```{r, echo=FALSE, eval=TRUE}
twoweeks.avgtests <- ggplot(twoweeksavg, aes(x=as.numeric(Group.1), y=Tests)) +
                      geom_line() + 
                      labs(x="Fortnights since August 1", title="Average Tests Over Time Period", 
                           subtitle = "Temporal mean, t=14")
twsat <- ggplotly(twoweeks.avgtests, height=625, width=1100)
twsat
```



Total Tests per Unit Time {data-navmenu="Testing"}
=====================================  
Inputs {.sidebar}
-----------------------------------------------------------------------
  
Cumulative tests per week/fortnight. Since the University said they would be performing appx. 400 tests per week, we can check this. The University claimed this would be Monday-Friday, but I included the weekends in order to catch any tests that may have slipped through. Additionally, this isn't only surveillance tests. This is all tests. Since the University doesn't distinguish between surveillance tests, and tests for contact tracing, I didn't either. For a vast majority of the semester, the University appears to have failed in their testing goals. Expanding into fortnights (2 week blocks) doesn't make it look much better, if we expect to see appx 800 tests per 14 day period.  
**NOTE:**  
Since the creation of this dashboard, Dean Runner responded to an email expressing my concerns and questions regarding the underlying data. According to this reply, there were approximately 3200 students. To quote Dean Runner on the number 400 was reached: "The number 400 was determined in consultation with Dr. Rob Strawderman, the Chair of Biostatistics in the Medical Center, who worked with the team to identify an appropriate threshold at which we could be confident that a certain number of positive results in a week would indicate a certain level of infection increase."  
My thanks to Dean Runner for this information.  


**Cases in past 24 hours:**  
`r data[nrow(data), 3]`  
**Tests in past 24 hours:**  
`r data[nrow(data), 2]`  
**Positivity Rate in Past 24 Hours:**  
`r data[nrow(data), 4]*100`\%  

Row {.tabset}
-----------------------------------------------------------------------

### 7 day blocks

```{r, echo=FALSE, eval=TRUE}
oneweek.sumtests <- ggplot(oneweeksum, aes(x=as.numeric(Group.1), y=Tests)) +
                      geom_line() + 
                      labs(x="Weeks since August 1", title="Cumulative Tests Time Period")
owst <- ggplotly(oneweek.sumtests, height=625, width=1100)
owst
```




### 14 day blocks

```{r, echo=FALSE, eval=TRUE}
twoweeks.sumtests <- ggplot(twoweekssum, aes(x=as.numeric(Group.1), y=Tests)) +
                      geom_line() + 
                      labs(x="Fortnights since August 1", title="Cumulative Tests Time Period")
twst <- ggplotly(twoweeks.sumtests, height=625, width=1100)
twst
```



A Note About GAMs
=====================================  

### GAMs and GAM smoothing

The graphs marked "Smoothed with a GAM" are exactly that: the raw lineplot, but smoothed with a Generalized Additive Model (GAM). These are **NOT** forecasts. While I am in the process of learning more about time series analysis and ML methods for forcasting at various time steps, I am not an epidemiologist and there are many, many wonderful people out there doing forecasts for COVID-19 cases/deaths who already know what they're doing (and do it really, really well).  
So why do I include these charts at all, then? Humans are really not great at interpreting raw lineplots for time series data. In the short term they're super jagged and don't provide super clear information for how things are changing over time. This is where smoothing helps. By smoothing the data, it's easier to see how the given Y-axis data changes with respect to time. Since it's smoothed, it loses a level of precision/accuracy, so it is by no means the best way to approach it, but the convenience of GAM smoothing being built into `ggplot2` combined with "good enough" accuracy made it my first choice. If anyone has a better idea/technique that I didn't think of, please reach out to me at `elisun@me.com`. I don't want to be misrepresenting any of the data, so I'm open to suggestions for how I can improve it.

