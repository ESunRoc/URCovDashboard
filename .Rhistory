```
### Smoothed with a GAM
```{r}
GAM.cpd
```
Tests per day {data-navmenu="Testing"}
=====================================
Inputs {.sidebar}
-----------------------------------------------------------------------
Average tests performed per day. The same as rolling average tests per day, but markedly worse for the reasons mentioned in "Rolling (+) Rate." Not without value, just eclipsed if you are looking for a sense of change over time.
**NOTE:**
Since the creation of this dashboard, Dean Runner responded to an email expressing my concerns and questions regarding the underlying data. According to this reply, there were approximately 3200 students. To quote Dean Runner on the number 400 was reached: "The number 400 was determined in consultation with Dr. Rob Strawderman, the Chair of Biostatistics in the Medical Center, who worked with the team to identify an appropriate threshold at which we could be confident that a certain number of positive results in a week would indicate a certain level of infection increase."
My thanks to Dean Runner for this information.
**Date:**
`r  data[nrow(data),1]`
**Cases in past 24 hours:**
`r data[nrow(data), 3]`
**Tests in past 24 hours:**
`r data[nrow(data), 2]`
**Positivity Rate in Past 24 Hours:**
`r data[nrow(data), 4]*100`\%
Row {.tabset data-height=675}
-----------------------------------------------------------------------
### Raw lineplot
```{r}
tpd
```
### Smoothed with a GAM
```{r}
GAM.tpd
```
Average Tests per Unit Time {data-navmenu="Testing"}
=====================================
Inputs {.sidebar}
-----------------------------------------------------------------------
Average tests per day per week/fortnight. This is primarily for keeping the University honest. For similar reasons as outlined in "Rolling tests/day," this metric allows us to see just how many tests the University is conducting, on average, over time. By blocking the average by week, we hopefully reduce the variation created by potentially having more than 2 weekend (ie, "low to zero" testing days) days included in the average at any given time. We also block by fortnight (2 weeks, for the uninitiated) to simulate the "14-day windows" that NYS uses as blocks.
**NOTE:**
Since the creation of this dashboard, Dean Runner responded to an email expressing my concerns and questions regarding the underlying data. According to this reply, there were approximately 3200 students. To quote Dean Runner on the number 400 was reached: "The number 400 was determined in consultation with Dr. Rob Strawderman, the Chair of Biostatistics in the Medical Center, who worked with the team to identify an appropriate threshold at which we could be confident that a certain number of positive results in a week would indicate a certain level of infection increase."
My thanks to Dean Runner for this information.
**Date:**
`r  data[nrow(data),1]`
**Cases in past 24 hours:**
`r data[nrow(data), 3]`
**Tests in past 24 hours:**
`r data[nrow(data), 2]`
**Positivity Rate in Past 24 Hours:**
`r data[nrow(data), 4]*100`\%
Row {.tabset data-height=675}
-----------------------------------------------------------------------
### 7 day blocks
```{r}
owat
```
### 14 day blocks
```{r}
twsat
```
Total Tests per Unit Time {data-navmenu="Testing"}
=====================================
Inputs {.sidebar}
-----------------------------------------------------------------------
Cumulative tests per week/fortnight. Since the University said they would be performing appx. 400 tests per week, we can check this. The University claimed this would be Monday-Friday, but I included the weekends in order to catch any tests that may have slipped through. Additionally, this isn't only surveillance tests. This is all tests. Since the University doesn't distinguish between surveillance tests, and tests for contact tracing, I didn't either. For a vast majority of the semester, the University appears to have failed in their testing goals. Expanding into fortnights (2 week blocks) doesn't make it look much better, if we expect to see appx 800 tests per 14 day period.
**NOTE:**
Since the creation of this dashboard, Dean Runner responded to an email expressing my concerns and questions regarding the underlying data. According to this reply, there were approximately 3200 students. To quote Dean Runner on the number 400 was reached: "The number 400 was determined in consultation with Dr. Rob Strawderman, the Chair of Biostatistics in the Medical Center, who worked with the team to identify an appropriate threshold at which we could be confident that a certain number of positive results in a week would indicate a certain level of infection increase."
My thanks to Dean Runner for this information.
**Date:**
`r  data[nrow(data),1]`
**Cases in past 24 hours:**
`r data[nrow(data), 3]`
**Tests in past 24 hours:**
`r data[nrow(data), 2]`
**Positivity Rate in Past 24 Hours:**
`r data[nrow(data), 4]*100`\%
Row {.tabset data-height=675}
-----------------------------------------------------------------------
### 7 day blocks
```{r}
owst
```
### 14 day blocks
```{r}
twst
```
A Note About GAMs
=====================================
### GAMs and GAM smoothing
The graphs marked "Smoothed with a GAM" are exactly that: the raw lineplot, but smoothed with a Generalized Additive Model (GAM). These are **NOT** forecasts. Not only do I not know forecast without knowing the underlying population size and several other key measures, but I don't know how to do it at all. While I could learn, I am not an epidemiologist and there are many, many wonderful people out there doing forecasts for COVID-19 cases/deaths who already know what they're doing (and do it really, really well).
So why do I include these charts at all, then? Humans are really not great at interpreting raw lineplots for time series data. In the short term they're super jagged and don't provide super clear information for how things are changing over time. This is where smoothing helps. By smoothing the data, it's easier to see how the given Y-axis data changes with respect to time. Since it's smoothed, it loses a level of precision/accuracy, so it is by no means the best way to approach it, but the convenience of GAM smoothing being built into `ggplot2` combined with "good enough" accuracy made it my first choice. If anyone has a better idea/technique that I didn't think of, please reach out to me at `elisun@me.com`. I don't want to be misrepresenting any of the data, so I'm open to suggestions for how I can improve it.
install.packages("plotly")
install.packages("plotly")
install.packages("plotly")
devtools::install_github("ropensci/plotly")
install.packages("plotly")
install.packages("plotly")
library(plotly)
shiny::runApp('Dashboard')
library(readxl)
library(tidyverse)
library(tidyverse)
library(zoo)
library(RcppRoll)
library(gridExtra)
library(grid)
library(plotly)
library(tidyverse)
library(zoo)
library(RcppRoll)
library(gridExtra)
library(grid)
library(plotly)
library(htmlwidgets)
data <- read_xlsx("covdata.xlsx")
data$daily.prate <- ifelse(data$Tests == 0, 0, data$Positive/data$Tests)
data$totcases <- cumsum(data$Positive)
data$tottests <- cumsum(data$Tests)
data$rolltests <- rollmean(data$Tests, k=7, fill=F, align="right")
data$rollpos <- rollmean(data$Positive, k=7, fill=F, align="right")
data$rolldaily.prate <- rollmean(data$daily.prate, k=7, fill=NA, align="right")
n.colfunc <- function(df, n=7, func){
aggregate(x = df,
by = list(gl(ceiling(nrow(df)/n), n)[1:nrow(df)]),
FUN = func)
}
twoweeksavg <- n.colfunc(data[2:4], 14, mean)
twoweeksavg
print(twoweeksavg)
cc
twoweeksavg <- n.colfunc(data[2:4], 14, mean)
oneweekavg <- n.colfunc(data[2:4], 7, mean)
twoweekssum <- n.colfunc(data[2:4], 14, sum)
oneweeksum <- n.colfunc(data[2:4], 7, sum)
cumlcases <- ggplot(data, aes(x = Date, y = totcases)) +
geom_line() +
scale_y_continuous(breaks=seq(0, max(data$totcases)+5 ,5)) +
labs(x = "Date", y = "Total Cases (to Date)", title = "Cumulative cases as a function of time")
cc <- ggplotly(cumlcases)
GAM.cumlcases <- ggplot(data, aes(x = Date, y = totcases)) +
geom_smooth(method = "gam", size = 1) +
scale_y_continuous(breaks=seq(0, max(data$totcases)+5 ,5)) +
labs(x = "Date", y = "Total Cases (to Date)", title = "Cumulative cases as a function of time")
GAM.cc <- ggplotly(GAM.cumlcases)
cumltests <- ggplot(data, aes(x = Date, y = tottests)) +
geom_line() +
labs(x = "Date", y = "Number of Tests", title = "Cumulative Testing as a function of time")
ct <- ggplotly(cumltests)
GAM.cumltests <- ggplot(data, aes(x = Date, y = tottests)) +
geom_smooth(method = "gam", size = 1) +
labs(x = "Date", y="Number of Tests", title = "Cumulative Testing as a function of time")
GAM.ct <- ggplotly(GAM.cumltests)
dailyposrate <- ggplot(data, aes(x = Date, y = daily.prate)) +
geom_line() +
labs(x = "Date", y = "Positivity Rate", title = "Daily positivity rate",
subtitle = "Aligned right")
dpr <- ggplotly(dailyposrate)
GAM.dailyposrate <- ggplot(data, aes(x = Date, y = daily.prate)) +
geom_smooth(method = "gam", size = 1) +
labs(x = "Date", y = "Positivity Rate", title = "Daily positivity rate",
subtitle = "Aligned right")
GAM.dpr <- ggplotly(GAM.dailyposrate)
rollposrate <- ggplot(data, aes(x = Date, y = rolldaily.prate)) +
geom_line() +
labs(x = "Date", y = "Positivity Rate", title = "7 day rolling positivity rate",
subtitle = "Aligned right")
rpr <- ggplotly(rollposrate)
GAM.rollposrate <- ggplot(data, aes(x = Date, y = rolldaily.prate)) +
geom_smooth(method = "gam", size = 1) +
labs(x = "Date", y = "Positivity Rate", title = "7 day rolling positivity rate",
subtitle = "Aligned right")
GAM.rpr <- ggplotly(GAM.rollposrate)
rolltestsgraph <- ggplot(data, aes(x=Date, y=rolltests)) +
geom_line()+
labs(x="Date", y="Tests Conducted", title = "7 day rolling tests per day",
subtitle = "Aligned Right")
rtg <- ggplotly(rolltestsgraph)
GAM.rolltestsgraph <- ggplot(data, aes(x=Date, y=rolltests)) +
geom_smooth(method = "gam", size = 1) +
labs(x="Date", y="Tests Conducted", title = "7 day rolling tests per day",
subtitle = "Aligned Right")
GAM.rtg <- ggplotly(GAM.rolltestsgraph)
casesperday <- ggplot(data, aes(x=Date, y=Positive)) +
geom_line()+
labs(x = "Date", y = "Cases", title = "New cases per day")
cpd <- ggplotly(casesperday)
GAM.casesperday <- ggplot(data, aes(x=Date, y=Positive)) +
geom_smooth()+
labs(x = "Date", y = "Cases", title = "New cases per day")
GAM.cpd <- ggplotly(GAM.casesperday)
testsperday <- ggplot(data, aes(x=Date, y=Tests)) +
geom_line()+
labs(x = "Date", y = "Tests", title = "Tests per day")
tpd <- ggplotly(testsperday)
GAM.testsperday <- ggplot(data, aes(x=Date, y=Tests)) +
geom_smooth(method = "gam", size=1)+
labs(x = "Date", y = "Tests", title = "Tests per day")
GAM.tpd <- ggplotly(GAM.testsperday)
# oneweek.sumtests <- ggplot(oneweeksum, aes(x=Date, y=Tests)) +
#                       geom_line() +
#                       labs(x="Weeks since August 1", title="Cumulative Tests Time Period")
# owst <- ggplotly(oneweek.sumtests)
#
#
# twoweeks.sumtests <- ggplot(twoweekssum, aes(x=Group.1, y=Tests)) +
#                       geom_line() +
#                       labs(x="Fortnights since August 1", title="Cumulative Tests Time Period")
# twst <- ggplotly(twoweeks.sumtests)
```
cc
# Chunk 1: global
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(tidyverse)
library(zoo)
library(RcppRoll)
library(gridExtra)
library(grid)
library(plotly)
library(htmlwidgets)
data <- read_xlsx("covdata.xlsx")
data$daily.prate <- ifelse(data$Tests == 0, 0, data$Positive/data$Tests)
data$totcases <- cumsum(data$Positive)
data$tottests <- cumsum(data$Tests)
data$rolltests <- rollmean(data$Tests, k=7, fill=F, align="right")
data$rollpos <- rollmean(data$Positive, k=7, fill=F, align="right")
data$rolldaily.prate <- rollmean(data$daily.prate, k=7, fill=NA, align="right")
n.colfunc <- function(df, n=7, func){
aggregate(x = df,
by = list(gl(ceiling(nrow(df)/n), n)[1:nrow(df)]),
FUN = func)
}
twoweeksavg <- n.colfunc(data[2:4], 14, mean)
oneweekavg <- n.colfunc(data[2:4], 7, mean)
twoweekssum <- n.colfunc(data[2:4], 14, sum)
oneweeksum <- n.colfunc(data[2:4], 7, sum)
cumlcases <- ggplot(data, aes(x = Date, y = totcases)) +
geom_line() +
scale_y_continuous(breaks=seq(0, max(data$totcases)+5 ,5)) +
labs(x = "Date", y = "Total Cases (to Date)", title = "Cumulative cases as a function of time")
cc <- ggplotly(cumlcases, height=500, width=1000)
GAM.cumlcases <- ggplot(data, aes(x = Date, y = totcases)) +
geom_smooth(method = "gam", size = 1) +
scale_y_continuous(breaks=seq(0, max(data$totcases)+5 ,5)) +
labs(x = "Date", y = "Total Cases (to Date)", title = "Cumulative cases as a function of time")
GAM.cc <- ggplotly(GAM.cumlcases, height=500, width=1000)
cumltests <- ggplot(data, aes(x = Date, y = tottests)) +
geom_line() +
labs(x = "Date", y = "Number of Tests", title = "Cumulative Testing as a function of time")
ct <- ggplotly(cumltests, height=500, width=1000)
GAM.cumltests <- ggplot(data, aes(x = Date, y = tottests)) +
geom_smooth(method = "gam", size = 1) +
labs(x = "Date", y="Number of Tests", title = "Cumulative Testing as a function of time")
GAM.ct <- ggplotly(GAM.cumltests, height=500, width=1000)
dailyposrate <- ggplot(data, aes(x = Date, y = daily.prate)) +
geom_line() +
labs(x = "Date", y = "Positivity Rate", title = "Daily positivity rate",
subtitle = "Aligned right")
dpr <- ggplotly(dailyposrate, height=500, width=1000)
GAM.dailyposrate <- ggplot(data, aes(x = Date, y = daily.prate)) +
geom_smooth(method = "gam", size = 1) +
labs(x = "Date", y = "Positivity Rate", title = "Daily positivity rate",
subtitle = "Aligned right")
GAM.dpr <- ggplotly(GAM.dailyposrate, height=500, width=1000)
rollposrate <- ggplot(data, aes(x = Date, y = rolldaily.prate)) +
geom_line() +
labs(x = "Date", y = "Positivity Rate", title = "7 day rolling positivity rate",
subtitle = "Aligned right")
rpr <- ggplotly(rollposrate, height=500, width=1000)
GAM.rollposrate <- ggplot(data, aes(x = Date, y = rolldaily.prate)) +
geom_smooth(method = "gam", size = 1) +
labs(x = "Date", y = "Positivity Rate", title = "7 day rolling positivity rate",
subtitle = "Aligned right")
GAM.rpr <- ggplotly(GAM.rollposrate, height=500, width=1000)
rolltestsgraph <- ggplot(data, aes(x=Date, y=rolltests)) +
geom_line()+
labs(x="Date", y="Tests Conducted", title = "7 day rolling tests per day",
subtitle = "Aligned Right")
rtg <- ggplotly(rolltestsgraph, height=500, width=1000)
GAM.rolltestsgraph <- ggplot(data, aes(x=Date, y=rolltests)) +
geom_smooth(method = "gam", size = 1) +
labs(x="Date", y="Tests Conducted", title = "7 day rolling tests per day",
subtitle = "Aligned Right")
GAM.rtg <- ggplotly(GAM.rolltestsgraph, height=500, width=1000)
casesperday <- ggplot(data, aes(x=Date, y=Positive)) +
geom_line()+
labs(x = "Date", y = "Cases", title = "New cases per day")
cpd <- ggplotly(casesperday, height=500, width=1000)
GAM.casesperday <- ggplot(data, aes(x=Date, y=Positive)) +
geom_smooth()+
labs(x = "Date", y = "Cases", title = "New cases per day")
GAM.cpd <- ggplotly(GAM.casesperday, height=500, width=1000)
testsperday <- ggplot(data, aes(x=Date, y=Tests)) +
geom_line()+
labs(x = "Date", y = "Tests", title = "Tests per day")
tpd <- ggplotly(testsperday, height=500, width=1000)
GAM.testsperday <- ggplot(data, aes(x=Date, y=Tests)) +
geom_smooth(method = "gam", size=1)+
labs(x = "Date", y = "Tests", title = "Tests per day")
GAM.tpd <- ggplotly(GAM.testsperday, height=500, width=1000)
oneweek.avgtests <- ggplot(oneweekavg, aes(x=Date, y=Tests)) +
geom_line() +
labs(x="Weeks since August 1", title="Average Tests Over Time Period",
subtitle = "Temporal mean, t=7")
owat <- ggplotly(oneweek.avgtests, height=500, width=1000)
twoweeks.avgtests <- ggplot(twoweeksavg, aes(x=Date, y=Tests)) +
geom_line() +
labs(x="Fortnights since August 1", title="Average Tests Over Time Period",
subtitle = "Temporal mean, t=14")
twsat <- ggplotly(twoweeks.avgtests, height=500, width=1000)
oneweek.sumtests <- ggplot(oneweeksum, aes(x=Date, y=Tests)) +
geom_line() +
labs(x="Weeks since August 1", title="Cumulative Tests Time Period")
owst <- ggplotly(oneweek.sumtests, height=500, width=1000)
twoweeks.sumtests <- ggplot(twoweekssum, aes(x=Group.1, y=Tests)) +
geom_line() +
labs(x="Fortnights since August 1", title="Cumulative Tests Time Period")
twst <- ggplotly(twoweeks.sumtests, height=500, width=1000)
# Chunk 2
cc
# Chunk 3
ct
# Chunk 4
dpr
# Chunk 5
GAM.dpr
# Chunk 6
rpr
# Chunk 7
GAM.rpr
# Chunk 8
rtg
# Chunk 9
GAM.rtg
# Chunk 10
cpd
# Chunk 11
GAM.cpd
# Chunk 12
tpd
# Chunk 13
GAM.tpd
# Chunk 14
owat
# Chunk 15
twsat
# Chunk 16
owst
# Chunk 17
twst
owst
owst <- ggplotly(oneweek.sumtests, height=500, width=1000)
oneweek.avgtests <- ggplot(oneweekavg, aes(x=Group.1, y=Tests)) +
geom_line() +
labs(x="Weeks since August 1", title="Average Tests Over Time Period",
subtitle = "Temporal mean, t=7")
owat <- ggplotly(oneweek.avgtests, height=500, width=1000)
owat
library(readxl)
library(tidyverse)
library(tidyverse)
library(zoo)
library(RcppRoll)
library(gridExtra)
library(grid)
library(plotly)
library(htmlwidgets)
data <- read_xlsx("covdata.xlsx")
View(data)
sum(data$Positive)
devtools::install_github("jakesherman/easypackages")
install.packages("e1071")
install.packages("caret")
library(forecast)
library(readxl)
data <- read_xlsx("covdata.xlsx")
y <- ts(data$Positive, frequency = 7)
fit <- ets(y)
View(fit)
fc <- forecast(fit)
plot(fc)
tsdisplay(y)
y <- ts(data$Positive, frequency = 7)
tsdisplay(y)
mod_1 <- Arima(y, order=c(1,0,1))
fdata <- forecast(mod_1, h=3)
fdata
plot(fdata)
fdata <- forecast(mod_1, h=5)
fdata
plot(fdata)
data$totcases <- cumsum(data$Positive)
data$daily.prate <- ifelse(data$Tests<data$Positive, 1, ifelse(data$Tests==0, 0, data$Positive/data$Tests))
y <- ts(data$totcases, frequency = 7)
tsdisplay(y)
mod_1 <- Arima(y, order=c(1,0,1))
mod_1 <- Arima(y, order=c(1,1,1))
fdata <- forecast(mod_1, h=5)
fdata
plot(fdata)
mod_1 <- Arima(y, order=c(1,1,3))
fdata <- forecast(mod_1, h=5)
fdata
plot(fdata)
mod_1 <- Arima(y, order=c(1,1,7))
mod_1 <- Arima(y, order=c(1,1,6))
library(caret)
library(e1071)
data <- read_xlsx("covdata.xlsx")
data$totcases <- cumsum(data$Positive)
rmse <- function(error){
sqrt(mean(error^2))
}
linmod <- lm(totcases, Day, data=data)
linmod <- lm(totcases~Day, data=data)
View(data)
data$day <- c(seq(1, len(data$Date)))
data$day <- c(seq(1, length(data$Date)))
linmod <- lm(totcases~day, data=data)
lin_prediction <- predict(linmod, data)
points(data$totcases, lin_prediction, col="blue", pch=4)
plot(data, pch=16)
plot(data$totcases, pch=16)
points(data$totcases, lin_prediction, col="blue", pch=4)
linmod <- lm(totcases~day, data)
lin_prediction <- predict(linmod, data)
plot(data$totcases, pch=16)
points(data$totcases, lin_prediction, col="blue", pch=4)
linmod <- lm(day~totcases, data)
lin_prediction <- predict(linmod, data)
plot(data$totcases, pch=16)
points(data$totcases, lin_prediction, col="blue", pch=4)
linmod <- lm(totcases~day, data)
rmse(linmod$residuals)
linmod <- lm(totcases~day, data)
lin_prediction <- predict(linmod, data)
plot(data$totcases, pch=16)
points(data$totcases, lin_prediction, col="blue", pch=4)
rmse(linmod$residuals)
linmod_error <- rmse(linmod$residuals)
svm_mod1 <- svm(totcases~day, data)
svm1_prediction <- predict(svm_mod1, data)
plot(data$totcases, pch=16)
points(data$totcases, svm1_prediction, col="blue", pch=4)
svm1_error <- data$totcases - svm1_prediction
svm1_rmse <- rmse(svm1_error)
tune1 <- tune(svm, totcases~day, data=data,
ranges = list(epsilon = seq(0,1,0.1), cost = 2^(2:9)))
tune1
print(tune1)
plot(tune1)
View(tune1)
tune1_error <- sqrt(tune1$best.performance)
tune2 <- tune(svm, totcases~day, data=data,
ranges = list(epsilon = seq(0,.25, .01), cost = 2^(2^9)))
View(tune2)
sqrt(tune2$best.performance)
library(forecast)
library(readxl)
data <- read_xlsx("covdata.xlsx")
data$day <- c(seq(1, length(data$Date)))
data$totcases <- cumsum(data$Positive)
data$daily.prate <- ifelse(data$Tests<data$Positive, 1, ifelse(data$Tests==0, 0, data$Positive/data$Tests))
y <- ts(data$totcases, frequency = 7)
tsdisplay(y)
ts_totcases <- ts(data$totcases, frequency = 7)
rm(y)
tsdisplay(ts_totcases)
ts_positive <- ts(data$Positive)
ts_positive
tsdisplay(ts_positive)
ts_positive <- ts(data$Positive, frequency=7)
tsdisplay(ts_positive)
ts_positive <- ts(data$Positive, frequency=10)
tsdisplay(ts_positive)
ts_positive <- ts(data$Positive, frequency=7)
tsdisplay(ts_positive)
ts_positive <- ts(data$Positive, frequency=1)
tsdisplay(ts_positive)
ts_totcases <- ts(data$totcases, frequency = 1)
tsdisplay(ts_totcases)
ts_positive <- ts(data$Positive, frequency=1)
tsdisplay(ts_positive)
ts_totcases_diff1 <- diff(ts_totcases, lag=1)
tm <- cbind(ts_totcases, ts_totcases_diff1)
head(tm)
plot.ts(tm)
eps <- rnorm(100, mean=0, sd=1)
eps <- rnorm(100, mean=0, sd=1)
mu <- 2
X_t <- mu + eps
ts.plot(X_t, main = "Example of (random) stationary time series", ylab = expression(X[t]))
acf(X_t, main="Auto-covariance function of X")
Z <- rnorm(100, mean=.5, sd=1.5)
for (i in 2:length(Z)){
X[i] <- X[i-1] + Z[i]
}
X <- 0
Z <- rnorm(100, mean=.5, sd=1.5)
for (i in 2:length(Z)){
X[i] <- X[i-1] + Z[i]
}
i
ts.plot(X, main="Random Walk process")
ts.plot(diff(X))
Z <- rnorm(100, mean = 0, sd = 1.5)
X <- c()
for (i in 2:length(Z)) {
X[i] <- Z[i] - .45*Z[i-1]
}
ts.plot(X, main="MA of order 1")
library(readxl)
data <- read_xlsx("covdata.xlsx")
data$totcases <- cumsum(data$Positive)
data$tottests <- cumsum(data$Tests)
